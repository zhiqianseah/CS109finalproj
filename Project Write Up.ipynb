{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reception of Films from Locations and Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents\n",
    "* [Reception of Films from Locations and Genres](#Reception-of-Films-from-Locations-and-Genres)\n",
    "    * [1. Overview](#1.-Overview)\n",
    "\t* [2. Data Acquisition & Management](#2.-Data-Acquisition-&-Management)\n",
    "        * [2.1. Approach 1](#2.1.-Approach-1)\n",
    "        * [2.2. Approach 2](#2.2.-Approach-2) \n",
    "    * [3. Analyses](#3.-Analyses)\n",
    "        * [3.1. Summary Statistics of Data Set](#3.1.-Summary-Statistics-of-Data-Set)\n",
    "        * [3.2. Principal Component Analysis](#3.2.-Principal-Component-Analysis)\n",
    "        * [3.3. Train Test Splitting](#3.3.-Train-Test-Splitting)\n",
    "        * [3.4. Logistic Regression](#3.4.-Logistic-Regression)\n",
    "        * [3.5. K-Nearest Neighbours](#3.5.-K-Nearest-Neighbours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "# The \"requests\" library makes working with HTTP requests easier\n",
    "# than the built-in urllib libraries.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we study the relationship between film reception and other factors like filming locations and genres. Data will be scraped from [IMDB](http://www.imdb.com). Principal Component Analysis(PCA) will be used for dimensionality reduction of our data set. Then, logistic regression and k-Nearest Neighbours(kNN) will be used for classification. The accuracy of both estimators will be compared. Visualisation of results will be done via graphical plots and Tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Data Acquisition & Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first scrape the data from IMDB which gives us information about each film title such as budget, country, critic ratings, duration, genre, gross earnings, language, location, name, opening weekend earnings, release dates, url, user ratings, user ratings count and year. Though we planned to work with a data set of 12,000 titles initially, a preliminary test run of PCA, particularly with around 18,000 features of locations and genres, indicated that it was infeasible. Instead, we reduce the size of our data to 10,000 title. To do so, we scraped IMDB for all film titles from 2009 to 2014. Titles without user ratings, film locations and genres are then removed from our data set. Subsequently, we pick 10,000 titles randomly from the remaining pool of titles.\n",
    "\n",
    "First, we convert user ratings to a binary feature where \"1\" indicates that the film was well-received while \"0\" indicates otherwise. Initially, the threshold rating for determining if a film is well-received was not \"5\" nor is it a randomly chosen number. Instead, we looked at the spread of user ratings across our data. Films with ratings in the top 50% were assigned \"1\" while films in the bottom 50% were assigned \"0\". Though such conversion of user ratings might raise problems, the intention here is to have a balanced number for both sides; additionally, this technique can be applied to larger data sets where the threshold is determined by the data in hand. However, after some considerations, it was decided that \"5\" will be taken as the threshold since \"5\" is the boundary most people use when deliberating whether or not they like a film.\n",
    "\n",
    "For locations, substantial data cleaning is required. This is largely due to film locations being user-contributed. Hence, we face problems like spelling mistakes, multiple entries of similar details or details with trivial differences that were irrelevant to our study. For example, some locations are specific to the street while others merely state the country. In cleaning up the feature \"locations\", we had considered two approaches which are elaborated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1. Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restrict \"locations\" to cities and countries. Using a list of cities, that we acquired online, and countries across the world, we split the entries of \"locations\" for each title by the commas into phrases. This is because most entries take the form - (specific location),(city),(country) - with various titles having anomalous and repeated entries. Phrases that appear in the list of cities and countries are kept while other location details are discarded. While this resulted in some problems, one particularly interesting issue was that many countries had names shared by cities. \n",
    "\n",
    "For example, China turned out to be the name of a city in Texas as well. As a result, if a film was filmed in China, Texas, it would be recorded as being filmed in the country China as well. However, given that these cities with similar names to countries are not especially known widely, we assume that such occurrences are rare anomalies. In addition, we chose to include countries so as to mitigate this problem since our hypothetical film will be recorded as being filmed in China and USA. As such, it is true that the film was filmed in USA but merely a rare anomaly that it is erroneously recorded to be filmed in China too.\n",
    "\n",
    "While Approach 2 below was also considered, Approach 1 was taken instead due to the complexity of the latter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2. Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split the entries of \"locations\" by commas and treat each unique phrase as a distinct location. For example, suppose we have \"Newbury Street, Boston, USA, Boston, USA\". We split them into \"Newbury Street\", \"Boston\" and \"USA\". From a data set of around 18,000 titles, we end up with around 19,000 distinct locations as features. Then, we rely on PCA to reduce the number of features into principal components.\n",
    "\n",
    "However, preliminary tests concluded that the computational demands of this approach was too immense. The number of components to be reduced to by PCA was intended to explain 90% of the variation in our features. While it was possible to find that number with our data set, the first few test runs simply took too long, prompting us to turn to the first approach instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df_input = pd.read_csv('df_boolean_temp2.csv',sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>budget</th>\n",
       "      <th>contentRating</th>\n",
       "      <th>country</th>\n",
       "      <th>critic_ratings</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre</th>\n",
       "      <th>gross</th>\n",
       "      <th>language</th>\n",
       "      <th>location_page</th>\n",
       "      <th>name</th>\n",
       "      <th>opening_weekend</th>\n",
       "      <th>release_dates</th>\n",
       "      <th>url</th>\n",
       "      <th>user_ratings</th>\n",
       "      <th>user_ratings_count</th>\n",
       "      <th>year</th>\n",
       "      <th>separated_places</th>\n",
       "      <th>separated_cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>€1,500,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110 min</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian</td>\n",
       "      <td>[Minsk, Belarus , Almaty, Kazakhstan , St. Pet...</td>\n",
       "      <td>Ya ne vernus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 1 March 2014 (Russia) ]</td>\n",
       "      <td>/title/tt2637844/</td>\n",
       "      <td>6.9</td>\n",
       "      <td>320</td>\n",
       "      <td>2014</td>\n",
       "      <td>[minsk, belarus, almaty, kazakhstan, st. peter...</td>\n",
       "      <td>[minsk, belarus, almaty, kazakhstan, russia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85 min</td>\n",
       "      <td>[Horror, Mystery, Thriller]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>[Silt, Colorado, USA ]</td>\n",
       "      <td>Find Me</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 1 September 2014 (USA) ]</td>\n",
       "      <td>/title/tt3027188/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>649</td>\n",
       "      <td>2014</td>\n",
       "      <td>[silt, colorado, usa]</td>\n",
       "      <td>[silt, colorado, usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88 min</td>\n",
       "      <td>[Comedy, Drama, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>[Dublin, County Dublin, Ireland , County Wickl...</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 10 October 2014 (Ireland) ]</td>\n",
       "      <td>/title/tt3134422/</td>\n",
       "      <td>6.1</td>\n",
       "      <td>406</td>\n",
       "      <td>2014</td>\n",
       "      <td>[dublin, county dublin, ireland, county wicklo...</td>\n",
       "      <td>[dublin, ireland, ireland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85 min</td>\n",
       "      <td>[Action, Sci-Fi, Thriller]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>[Los Angeles, California, USA , Long Beach, Ca...</td>\n",
       "      <td>Mega Shark vs. Mecha Shark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 28 January 2014 (USA) ]</td>\n",
       "      <td>/title/tt3152098/</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1,988</td>\n",
       "      <td>2014</td>\n",
       "      <td>[los angeles, california, usa, long beach, cal...</td>\n",
       "      <td>[los angeles, california, usa, long beach, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117 min</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Polish</td>\n",
       "      <td>[Ancona, Marche, Italy , Warsaw, Mazowieckie, ...</td>\n",
       "      <td>Obce cialo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ 5 December 2014 (Poland) ]</td>\n",
       "      <td>/title/tt3997248/</td>\n",
       "      <td>4.6</td>\n",
       "      <td>156</td>\n",
       "      <td>2014</td>\n",
       "      <td>[ancona, marche, italy, warsaw, mazowieckie, p...</td>\n",
       "      <td>[ancona, marche, italy, warsaw, poland, moscow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      budget contentRating     country critic_ratings duration                        genre gross language                                      location_page                        name opening_weekend                  release_dates                url  user_ratings user_ratings_count  year                                   separated_places                                   separated_cities\n",
       "0      0  €1,500,000           NaN  Kazakhstan            NaN  110 min                      [Drama]   NaN  Russian  [Minsk, Belarus , Almaty, Kazakhstan , St. Pet...                Ya ne vernus             NaN      [ 1 March 2014 (Russia) ]  /title/tt2637844/           6.9                320  2014  [minsk, belarus, almaty, kazakhstan, st. peter...       [minsk, belarus, almaty, kazakhstan, russia]\n",
       "1      3         NaN           NaN         USA            NaN   85 min  [Horror, Mystery, Thriller]   NaN  English                             [Silt, Colorado, USA ]                     Find Me             NaN     [ 1 September 2014 (USA) ]  /title/tt3027188/           4.5                649  2014                              [silt, colorado, usa]                              [silt, colorado, usa]\n",
       "2      4         NaN           NaN     Ireland            NaN   88 min      [Comedy, Drama, Family]   NaN  English  [Dublin, County Dublin, Ireland , County Wickl...                        Gold             NaN  [ 10 October 2014 (Ireland) ]  /title/tt3134422/           6.1                406  2014  [dublin, county dublin, ireland, county wicklo...                         [dublin, ireland, ireland]\n",
       "3     10         NaN           Not         USA            NaN   85 min   [Action, Sci-Fi, Thriller]   NaN  English  [Los Angeles, California, USA , Long Beach, Ca...  Mega Shark vs. Mecha Shark             NaN      [ 28 January 2014 (USA) ]  /title/tt3152098/           2.6              1,988  2014  [los angeles, california, usa, long beach, cal...  [los angeles, california, usa, long beach, cal...\n",
       "4     11         NaN           NaN      Poland            NaN  117 min             [Drama, Romance]   NaN   Polish  [Ancona, Marche, Italy , Warsaw, Mazowieckie, ...                  Obce cialo             NaN   [ 5 December 2014 (Poland) ]  /title/tt3997248/           4.6                156  2014  [ancona, marche, italy, warsaw, mazowieckie, p...  [ancona, marche, italy, warsaw, poland, moscow..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_input.drop('level_0', axis=1, inplace=True)\n",
    "new_df_input.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "new_df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get set of unique cities\n",
    "\n",
    "def unique_entries(input_df, field):\n",
    "    entries = set()\n",
    "    for row in input_df[field]:\n",
    "        for loc in row:\n",
    "            entries.add(loc)\n",
    "    return entries\n",
    "\n",
    "#clean the column by removing brackets from the reads\n",
    "def clean_column(input_df, field):\n",
    "    cleanedrowlist = []\n",
    "    for row in input_df[field]:\n",
    "        cleanedrow =  row.replace('[', '')\n",
    "        cleanedrow =  cleanedrow.replace(']', '')\n",
    "        cleanedrow = cleanedrow.split(\", \")\n",
    "        cleanedrowlist.append(cleanedrow)\n",
    "    input_df[field] = cleanedrowlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 10,000 random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "\n",
    "SAMPLESIZE = 10000\n",
    "\n",
    "newdf_boolean_sampled = new_df_input.copy()\n",
    "clean_column(newdf_boolean_sampled, \"separated_cities\")\n",
    "clean_column(newdf_boolean_sampled, \"genre\")\n",
    "\n",
    "rows = random.sample(newdf_boolean_sampled.index, SAMPLESIZE)\n",
    "newdf_boolean_sampled = newdf_boolean_sampled.ix[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4802\n"
     ]
    }
   ],
   "source": [
    "places3 = unique_entries(newdf_boolean_sampled, \"separated_cities\")\n",
    "if \"\" in places3:\n",
    "    places3.remove(\"\")\n",
    "if \"...\" in places3:\n",
    "    places3.remove(\"...\")\n",
    "print len(places3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "set([u'Sci-Fi', u'Crime', u'Romance', u'Animation', u'Music', u'Adult', u'Comedy', u'War', u'Horror', u'Western', u'News', u'Reality-TV', u'Thriller', u'Adventure', u'Mystery', u'Drama', u'Action', u'Musical', u'History', u'Family', u'Fantasy', u'Game-Show', u'Sport', u'Biography'])\n"
     ]
    }
   ],
   "source": [
    "genres3 = unique_entries(newdf_boolean_sampled, \"genre\")\n",
    "genres3.remove(\"\")\n",
    "print len(genres3) \n",
    "print genres3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsampleddf = pd.DataFrame()\n",
    "#create a column for each city, and set to true if that row contains that city\n",
    "for place in places3:\n",
    "        Xsampleddf[place] = [place in location for location in newdf_boolean_sampled.separated_cities]\n",
    "for genre in genres3:\n",
    "        Xsampleddf[genre] = [genre in genre_entries for genre_entries in newdf_boolean_sampled.genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsampleddf = Xsampleddf.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting user ratings and categorising them into well-received or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median(input_df):\n",
    "    rating_list = []\n",
    "    for x in input_df[\"user_ratings\"]:\n",
    "        if isinstance(x, (np.ndarray, np.generic) ):\n",
    "            rating_list.append(x)\n",
    "\n",
    "    print np.mean(rating_list)\n",
    "    ratingmedian = np.median(rating_list)\n",
    "    print ratingmedian\n",
    "    return ratingmedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ratingdf(inputdf):\n",
    "    ratingsdf = pd.DataFrame()\n",
    "    #ratingmedian = get_median(inputdf)\n",
    "    ratingmedian = 5\n",
    "    ratingslist = []\n",
    "    for x in range(len(inputdf)):\n",
    "        if inputdf[\"user_ratings\"].iloc[x] >= ratingmedian:\n",
    "            ratingslist.append(1)\n",
    "        else:\n",
    "            ratingslist.append(0)\n",
    "    ratingsdf[\"reception\"] = ratingslist\n",
    "    return ratingsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reception\n",
       "0          0\n",
       "1          1\n",
       "2          1\n",
       "3          0\n",
       "4          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsdf_sampled = get_ratingdf(newdf_boolean_sampled)\n",
    "ratingsdf_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data frame for descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.1\n",
       "1    5.8\n",
       "2    5.9\n",
       "3    4.1\n",
       "4    6.6\n",
       "Name: user_ratings, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_boolean_sampled = newdf_boolean_sampled.reset_index()\n",
    "newdf_boolean_sampled[\"user_ratings\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ratings</th>\n",
       "      <th>trenton</th>\n",
       "      <th>bartoszyce</th>\n",
       "      <th>brindisi</th>\n",
       "      <th>bad grund</th>\n",
       "      <th>green river</th>\n",
       "      <th>ilulissat</th>\n",
       "      <th>chigasaki</th>\n",
       "      <th>collegeville</th>\n",
       "      <th>wilton manors</th>\n",
       "      <th>sichuan</th>\n",
       "      <th>nottingham</th>\n",
       "      <th>saylorsburg</th>\n",
       "      <th>uithoorn</th>\n",
       "      <th>brantford</th>\n",
       "      <th>roslyn</th>\n",
       "      <th>crete</th>\n",
       "      <th>kassel</th>\n",
       "      <th>tajikistan</th>\n",
       "      <th>zittau</th>\n",
       "      <th>san ignacio</th>\n",
       "      <th>sherman oaks</th>\n",
       "      <th>jaipur</th>\n",
       "      <th>paris</th>\n",
       "      <th>gig harbor</th>\n",
       "      <th>islip</th>\n",
       "      <th>potomac</th>\n",
       "      <th>colorno</th>\n",
       "      <th>geyserville</th>\n",
       "      <th>el campello</th>\n",
       "      <th>las palmas de gran canaria</th>\n",
       "      <th>pushkin</th>\n",
       "      <th>bagalkot</th>\n",
       "      <th>chennai</th>\n",
       "      <th>stanton</th>\n",
       "      <th>puente de ixtla</th>\n",
       "      <th>freudenstadt</th>\n",
       "      <th>wausau</th>\n",
       "      <th>aurora</th>\n",
       "      <th>bryn mawr</th>\n",
       "      <th>folsom</th>\n",
       "      <th>mary esther</th>\n",
       "      <th>bratislava</th>\n",
       "      <th>koprivnica</th>\n",
       "      <th>rapid city</th>\n",
       "      <th>truchas</th>\n",
       "      <th>georgia</th>\n",
       "      <th>jenkintown</th>\n",
       "      <th>roissy-en-france</th>\n",
       "      <th>cape may</th>\n",
       "      <th>...</th>\n",
       "      <th>deggendorf</th>\n",
       "      <th>kirkwood</th>\n",
       "      <th>harefield</th>\n",
       "      <th>warner springs</th>\n",
       "      <th>vence</th>\n",
       "      <th>whitby</th>\n",
       "      <th>heide</th>\n",
       "      <th>tarrytown</th>\n",
       "      <th>brechin</th>\n",
       "      <th>carcassonne</th>\n",
       "      <th>banff</th>\n",
       "      <th>montrose</th>\n",
       "      <th>baker</th>\n",
       "      <th>makati city</th>\n",
       "      <th>lloret de mar</th>\n",
       "      <th>charenton-le-pont</th>\n",
       "      <th>merthyr tydfil</th>\n",
       "      <th>scotch plains</th>\n",
       "      <th>oeiras</th>\n",
       "      <th>foster city</th>\n",
       "      <th>nuuk</th>\n",
       "      <th>abergele</th>\n",
       "      <th>westfield</th>\n",
       "      <th>bierset</th>\n",
       "      <th>arenys de mar</th>\n",
       "      <th>creuzburg</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Music</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>War</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Western</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Action</th>\n",
       "      <th>Musical</th>\n",
       "      <th>History</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Game-Show</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Biography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ratings  trenton  bartoszyce  brindisi  bad grund  green river  ilulissat  chigasaki  collegeville  wilton manors  sichuan  nottingham  saylorsburg  uithoorn  brantford  roslyn  crete  kassel  tajikistan  zittau  san ignacio  sherman oaks  jaipur  paris  gig harbor  islip  potomac  colorno  geyserville  el campello  las palmas de gran canaria  pushkin  bagalkot  chennai  stanton  puente de ixtla  freudenstadt  wausau  aurora  bryn mawr  folsom  mary esther  bratislava  koprivnica  \\\n",
       "0           4.1        0           0         0          0            0          0          0             0              0        0           0            0         0          0       0      0       0           0       0            0             0       0      0           0      0        0        0            0            0                           0        0         0        0        0                0             0       0       0          0       0            0           0           0   \n",
       "1           5.8        0           0         0          0            0          0          0             0              0        0           0            0         0          0       0      0       0           0       0            0             0       0      0           0      0        0        0            0            0                           0        0         0        0        0                0             0       0       0          0       0            0           0           0   \n",
       "2           5.9        0           0         0          0            0          0          0             0              0        0           0            0         0          0       0      0       0           0       0            0             0       0      0           0      0        0        0            0            0                           0        0         0        0        0                0             0       0       0          0       0            0           0           0   \n",
       "3           4.1        0           0         0          0            0          0          0             0              0        0           0            0         0          0       0      0       0           0       0            0             0       0      0           0      0        0        0            0            0                           0        0         0        0        0                0             0       0       0          0       0            0           0           0   \n",
       "4           6.6        0           0         0          0            0          0          0             0              0        0           0            0         0          0       0      0       0           0       0            0             0       0      0           0      0        0        0            0            0                           0        0         0        0        0                0             0       0       0          0       0            0           0           0   \n",
       "\n",
       "   rapid city  truchas  georgia  jenkintown  roissy-en-france  cape may    ...      deggendorf  kirkwood  harefield  warner springs  vence  whitby  heide  tarrytown  brechin  carcassonne  banff  montrose  baker  makati city  lloret de mar  charenton-le-pont  merthyr tydfil  scotch plains  oeiras  foster city  nuuk  abergele  westfield  bierset  arenys de mar  creuzburg  Sci-Fi  Crime  Romance  Animation  Music  Adult  Comedy  War  Horror  Western  News  Reality-TV  Thriller  Adventure  \\\n",
       "0           0        0        0           0                 0         0    ...               0         0          0               0      0       0      0          0        0            0      0         0      0            0              0                  0               0              0       0            0     0         0          0        0              0          0       0      1        0          0      0      0       0    0       0        0     0           0         0          0   \n",
       "1           0        0        0           0                 0         0    ...               0         0          0               0      0       0      0          0        0            0      0         0      0            0              0                  0               0              0       0            0     0         0          0        0              0          0       0      1        0          0      0      0       1    0       0        0     0           0         0          0   \n",
       "2           0        0        0           0                 0         0    ...               0         0          0               0      0       0      0          0        0            0      0         0      0            0              0                  0               0              0       0            0     0         0          0        0              0          0       0      0        0          0      0      0       0    0       0        0     0           0         1          1   \n",
       "3           0        0        0           0                 0         0    ...               0         0          0               0      0       0      0          0        0            0      0         0      0            0              0                  0               0              0       0            0     0         0          0        0              0          0       0      0        0          0      0      0       0    0       1        0     0           0         0          0   \n",
       "4           0        0        0           0                 0         0    ...               0         0          0               0      0       0      0          0        0            0      0         0      0            0              0                  0               0              0       0            0     0         0          0        0              0          0       0      0        0          0      0      0       0    0       0        0     0           0         0          0   \n",
       "\n",
       "   Mystery  Drama  Action  Musical  History  Family  Fantasy  Game-Show  Sport  Biography  \n",
       "0        0      1       1        0        0       0        0          0      0          0  \n",
       "1        0      0       0        0        0       0        0          0      0          0  \n",
       "2        0      1       0        0        0       0        0          0      0          0  \n",
       "3        0      0       0        0        0       0        0          0      0          0  \n",
       "4        0      1       0        0        0       0        0          0      0          0  \n",
       "\n",
       "[5 rows x 4827 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsdf = pd.DataFrame()\n",
    "statsdf = pd.concat([newdf_boolean_sampled[\"user_ratings\"], Xsampleddf], axis=1)\n",
    "statsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.719843049327349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(statsdf[statsdf.usa==1].user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1. Summary Statistics of Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a better representations of the data set that we have, we will have some graphical plots of our data, like histograms across countries and genres. The large number of cities appearing in our data means that a histogram across all cities should be avoided. We can still study the frequency of the top few cities. Film reception can also be presented as a barplot.\n",
    "\n",
    "Potentially, we might want to look at the relation between locations and genres. For example, what is the probability that a title was filmed in New York conditional on it being a drama. We might be able to write a function where you input parameters $X$ and $Y$, each representing a location, which may be a city, country or genre, and it returns $Probability(X|Y)$.\n",
    "\n",
    "Other visualizations will be done using Tableau. For example, we can present the number of titles per city on a map in Tableau since we have city coordinates from the list of cities acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   25.,   117.,   323.,   676.,  1192.,  1955.,  2574.,  2083.,\n",
       "          927.,   128.]),\n",
       " array([ 1.  ,  1.79,  2.58,  3.37,  4.16,  4.95,  5.74,  6.53,  7.32,\n",
       "         8.11,  8.9 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwkAAAIbCAYAAACg8tKoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt/X+c13Wd7//fZyAEZhhNYTkqylhmoyYIhogHz4IHDe1S\n/ri41bnElnbItlXsrIpKwQXDE1wkxPUHOyT5g+14dlfNk2yXTuWip6wDspXBdpFYXZkVMoU56tQM\nk0Mwnz/8Mt+e8VtmeON4vV4uXC5dXu/n+zWP9+syjXOb1/v1eld1dnZ2BgAA4P+nutIDAAAAhxaR\nAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFPYaCR0dHbn99tszceLEjBo1Kp/+9Kfz7LPPFmsaGxsz\nYcKEnH766fnMZz6TF154Yad9zJ07N+PHj8/o0aNzzTXXZNOmTcWalpaW3HTTTRk7dmzOPPPMzJw5\nM62trd3wEgEAgP1RtbfPSfjyl7+cZcuWZfr06Rk+fHiWLl2an/zkJ1m2bFmOOeaY3H333VmyZEmm\nT5+eY445Jo2NjXnllVfyne98J7W1tUmSGTNm5IknnsiMGTMyYMCALFy4MAMGDMijjz6a6uo3O+VT\nn/pUfvWrX+WGG25Ie3t75s+fnxEjRmTx4sU9fxQAAIAufff04G9/+9s8/PDDuf766/OJT3wiSTJ6\n9OiMHTs2y5Yty5QpU3Lvvfdm2rRpmTJlSpLkgx/8YCZOnJhHHnkkl19+eV588cU89thjue2223LB\nBRckSRoaGjJ58uQsX7485513XlauXJlVq1bloYceyogRI5IkQ4cOzRVXXJFnn302p5xySk8eAwAA\n4A/s8e1GAwcOzCOPPJJLL720a1ufPn1SVVWVjo6OrF69Ou3t7Tn33HO7Hq+rq8uYMWPy1FNPJUlW\nrlyZJJk4cWLXmuHDh+fEE0/sWrNixYoMHjy4KxCSZOzYsamtre1aAwAAHBx7jIQ+ffqkoaEhdXV1\n6ezszIYNG/LFL34xVVVV+ehHP5qmpqYkyfHHH188b9iwYVm/fn2SZP369RkyZEj69++/05odz1+/\nfv1O+6iurs6xxx7btQYAADg49vnuRosWLcp5552XZcuW5bOf/Wzq6+vT2tqafv36pW/f8l1LNTU1\naWtrS5K0tbVl4MCBO+2vpqam68Lktra21NTU7LRm4MCBXfsBAAAOjj1ek/CHzjvvvJx11llZuXJl\nFi1alI6OjvTv3z9VVVW7XL/jguTOzs4DWrO77QAAQM/Y50h4//vfn+TNC5Pb2tpy77335vrrr09H\nR0e2bduWPn36dK1ta2vLoEGDkiS1tbW7PBvwx2uam5v3uAYAADg49hgJzc3N+cEPfpDJkycXbwdq\naGhIR0dH17UKGzduzPDhw7se37hxY0444YQkSX19fZqbm9PR0ZF+/foVa8aMGdO15plnnim+9vbt\n2/PSSy/loosu2u8X9dOf/nS/nwMAAO8EZ5xxxl7X7DESWlpa8qUvfSlVVVXFHY5+/OMfZ/DgwZk0\naVIOO+ywPP7445k6dWrXc1atWpVrrrkmSTJu3Lhs27Yty5cv77oFalNTU55//vlizT333JM1a9Z0\n3eHo6aefTmtra8aNG/cWXvq+vXjemrVr1yZJTj755ApP0ns5xj3PMT44HOee5xj3PMf44HCce97a\ntWuzZcuWfVq7x0h473vfm/PPPz+33nprtm7dmmHDhuX73/9+li1blnnz5qW2tjZTpkzJHXfckerq\n6gwfPjyLFy9OXV1dLrvssiRv3vlo8uTJmTVrVlpbWzNo0KAsXLgwDQ0NmTRpUpI3I2HkyJGZNm1a\nbrjhhmzdujW33nprJkyY4DMSAADgINvrNQnz58/P3Xffna997WvZvHlz3ve+9+XOO+/M+eefnyS5\n9tprU11dnfvuuy9tbW0ZPXp05s+f3/Vpy0kyb968zJs3LwsWLMj27dtz9tlnZ+bMmcVFyY2Njbnl\nllsya9as9OvXL5MmTcqMGTN64CUDAAB7UtXZ2dlZ6SG6209/+lNvN+pBTgf2PMe45znGB4fj3PMc\n457nGB8cjnPP2/F2o335PXmfPycBAAB4ZxAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAF\nkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABA\nQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAA\nUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAA\nABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQA\nAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJ\nAABAQSQAAACFvpUeAAB6u5aWlqxZs6ZH9t3U1JQkaW5u7pH997QRI0bk8MMPr/QYwB8RCQDQw9as\nWZPPz/5G6obU9+BX2dCD++4Zv9nclMYv/3nOOeecSo8C/BGRAAAHQd2Q+hw17NRKjwGwT1yTAAAA\nFEQCAABQEAkAAEBhr5Gwffv23H///bngggsyatSofPjDH86DDz7Y9fgvfvGLNDQ07PRv/vz5XWs6\nOjoyd+7cjB8/PqNHj84111yTTZs2FV+npaUlN910U8aOHZszzzwzM2fOTGtraze+VAAAYF/s9cLl\nRYsWZcmSJbnqqqsycuTI/OQnP8ncuXPT3t6eqVOn5pe//GUGDBiQpUuXFs/7kz/5k67/PXv27Dzx\nxBOZMWNGBgwYkIULF+bKK6/Mo48+murqNztl2rRp+dWvfpU5c+akvb098+fPT3NzcxYvXtzNLxkA\nANiTPUbCtm3b8sADD2Tq1Kn53Oc+lyQ566yz8uqrr+a+++7L1KlTs27durz//e/PiBEjdrmPF198\nMY899lhuu+22XHDBBUmShoaGTJ48OcuXL895552XlStXZtWqVXnooYe69jN06NBcccUVefbZZ3PK\nKad052sGAAD2YI9vN2pra8sll1yS888/v9heX1+fV199Ne3t7Vm3bl1OOumk3e5j5cqVSZKJEyd2\nbRs+fHhOPPHEPPXUU0mSFStWZPDgwUVojB07NrW1tV1rAACAg2OPZxLq6uoyc+bMnbY/+eSTOfro\nozNgwID867/+aw477LBcfPHFef7553PMMcfkL//yL3PxxRcnSdavX58hQ4akf//+xT6GDRvW9SmR\n69evz/HHH188Xl1dnWOPPbZrDQAAcHDs94epPfzww1mxYkVmzZqVTZs25fXXX8+LL76Ya6+9NnV1\ndfn2t7+dm266KUly8cUXp62tLQMHDtxpPzU1NXnllVeSvHnGoqamZqc1AwcOTFtb2/6OCAAAHID9\nioRly5bl5ptvzuTJk/PJT34yb7zxRu6///6cdNJJOeqoo5Ik48aNy6ZNm7Jo0aJcfPHF6ezsTFVV\n1S73t+Oi5T2t2d32vVm7du1beh57197ensQx7kmOcc9zjA8Ox/lNzorvXlNTUwYPHlzpMfbI9/HB\n4Tj3vB3HeF/s8+ck3H///bnxxhszceLELFiwIEly2GGHZdy4cV2BsMP48eOzYcOGbNmyJbW1tbs8\nG9DW1pZBgwYlSWpra3d5u9M/XAMAABwc+3QmYeHChbnnnntyySWX5Ctf+UrXGYD169dnxYoVueyy\ny9KvX7+u9W+88UYGDBiQgQMHpr6+Ps3Nzeno6CjWbNy4MWPGjEny5oXQzzzzTPE1t2/fnpdeeikX\nXXTRW3phJ5988lt6Hnu3o/Ad457jGPc8x/jgcJzf1NzcnGRDpcc4JNXX1x/y3x++jw8Ox7nnrV27\nNlu2bNmntXs9k7B06dLcc889+fSnP5158+Z1BUKSvPzyy5kzZ05++MMfdm3r7OzM97///ZxxxhlJ\n3nz70bZt27J8+fKuNU1NTXn++eczbty4rjWbN2/OmjVrutY8/fTTaW1t7VoDAAAcHHs8k7Bp06Ys\nWLAgJ510Ui688ML8/Oc/Lx4/44wzMmrUqMyePTstLS0ZPHhwHnrooTz33HP5u7/7uyTJ8ccfn8mT\nJ2fWrFlpbW3NoEGDsnDhwjQ0NGTSpElJ3oyEkSNHZtq0abnhhhuydevW3HrrrZkwYYLPSAAAgINs\nj5Hwox/9KFu3bs1zzz2Xj3/848VjVVVVWbFiRRobG7Nw4cLceeedef3113PqqafmvvvuK365nzdv\nXubNm5cFCxZk+/btOfvsszNz5sziouTGxsbccsstmTVrVvr165dJkyZlxowZ3fxyAQCAvdljJFx6\n6aW59NJL97qTOXPm7PHxAQMGZM6cOXtcd+SRR+b222/f69cCAAB61j7f3QgAAHhnEAkAAEBBJAAA\nAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkA\nAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQC\nAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWR\nAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBB\nJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEBBJAAAAAWRAAAAFEQCAABQ\nEAkAAEBBJAAAAAWRAAAAFEQCAABQEAkAAEChb6UHAADemX7f8busXr260mPsVVNTU5Kkubn5oH7d\nESNG5PDDDz+oXxN2EAkAQEVsaXk5ix99OXVP/abSo+yjDQftK/1mc1Mav/znOeeccw7a14Q/JBIA\ngIqpG1Kfo4adWukxgD/imgQAAKAgEgAAgIJIAAAACiIBAAAo7DUStm/fnvvvvz8XXHBBRo0alQ9/\n+MN58MEHizWNjY2ZMGFCTj/99HzmM5/JCy+8UDze0dGRuXPnZvz48Rk9enSuueaabNq0qVjT0tKS\nm266KWPHjs2ZZ56ZmTNnprW1tRteIgAAsD/2enejRYsWZcmSJbnqqqsycuTI/OQnP8ncuXPT3t6e\nqVOn5u67786SJUsyffr0HHPMMWlsbMzll1+e73znO6mtrU2SzJ49O0888URmzJiRAQMGZOHChbny\nyivz6KOPprr6zU6ZNm1afvWrX2XOnDlpb2/P/Pnz09zcnMWLF/fsEQAAAAp7jIRt27blgQceyNSp\nU/O5z30uSXLWWWfl1VdfzX333Zf/8l/+S+69995MmzYtU6ZMSZJ88IMfzMSJE/PII4/k8ssvz4sv\nvpjHHnsst912Wy644IIkSUNDQyZPnpzly5fnvPPOy8qVK7Nq1ao89NBDGTFiRJJk6NChueKKK/Ls\ns8/mlFNO6cljAAAA/IE9vt2ora0tl1xySc4///xie319fV599dWsXLky7e3tOffcc7seq6ury5gx\nY/LUU08lSVauXJkkmThxYtea4cOH58QTT+xas2LFigwePLgrEJJk7Nixqa2t7VoDAAAcHHs8k1BX\nV5eZM2futP3JJ5/M0UcfnZdffjlJcvzxxxePDxs2LE888USSZP369RkyZEj69++/05odH3O+fv36\nnfZRXV2dY489tmsNAABwcOz33Y0efvjhrFixIlOnTk1ra2v69euXvn3L1qipqUlbW1uSN89GDBw4\ncKf91NTUdF2Y3NbWlpqamp3WDBw4sGs/AADAwbHXC5f/0LJlyzJ79uxMnjw5n/zkJ7N48eJUVVXt\ncu2OC5I7OzsPaM3utu/N2rVr39Lz2Lv29vYkjnFPcox7nmN8cDjOb3JWnLeiqakpgwcPrvQYB42f\nFz1vxzHeF/t8JuH+++/PjTfemHPPPTcLFixIkgwaNCgdHR3Ztm1bsbatrS2DBg1KktTW1u7ybMAf\nr9nV7U7/cA0AAHBw7NOZhIULF+aee+7JJZdckq985StdZwCGDx+ezs7ObNy4McOHD+9av3Hjxpxw\nwglJ3rzIubm5OR0dHenXr1+xZsyYMV1rnnnmmeJrbt++PS+99FIuuuiit/TCTj755Lf0PPZuR+E7\nxj3HMe55jvHB4Ti/qbm5OcmGSo/B20x9ff076v87fl70vLVr12bLli37tHavZxKWLl2ae+65J5/+\n9Kczb968rkBIklGjRuWwww7L448/3rWtpaUlq1atyrhx45Ik48aNy7Zt27J8+fKuNU1NTXn++eeL\nNZs3b86aNWu61jz99NNpbW3tWgMAABwcezyTsGnTpixYsCAnnXRSLrzwwvz85z8vHj/ttNMyZcqU\n3HHHHamurs7w4cOzePHi1NXV5bLLLkvy5p2PJk+enFmzZqW1tTWDBg3KwoUL09DQkEmTJiV5MxJG\njhyZadOm5YYbbsjWrVtz6623ZsKECT4jAQAADrI9RsKPfvSjbN26Nc8991w+/vGPF49VVVVlxYoV\nufbaa1NdXZ377rsvbW1tGT16dObPn9/1actJMm/evMybNy8LFizI9u3bc/bZZ2fmzJnFRcmNjY25\n5ZZbMmvWrPTr1y+TJk3KjBkzuvnlAgAAe7PHSLj00ktz6aWX7nUn1113Xa677rrdPj5gwIDMmTMn\nc+bM2e2aI488MrfffvtevxYAANCz9vtzEgAAgN5tvz4nAQB2p6WlpbgBRfL//3yAN+/u8861evXq\nSo8AsF9EAgDdYs2aNfn87G+kbkj9Lh59Z9/+89fPrcjR73O3PuDtQyQA0G3qhtTnqGGnVnqMQ85v\nNjdVegSA/eKaBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCAS\nAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiI\nBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAK\nIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACA\ngkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAA\noCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEAACiIBAAAoCASAACAgkgAAAAKIgEA\nACiIBAAAoLBfkbB8+fKMHj262PaLX/wiDQ0NO/2bP39+15qOjo7MnTs348ePz+jRo3PNNddk06ZN\nxX5aWlpy0003ZezYsTnzzDMzc+bMtLa2HsBLAwAA3oq++7rwZz/7WaZPn77T9l/+8pcZMGBAli5d\nWmz/kz/5k67/PXv27DzxxBOZMWNGBgwYkIULF+bKK6/Mo48+murqNztl2rRp+dWvfpU5c+akvb09\n8+fPT3NzcxYvXvxWXxsAAPAW7DUSOjo6snTp0tx5550ZOHBgtm7dWjy+bt26vP/978+IESN2+fwX\nX3wxjz32WG677bZccMEFSZKGhoZMnjw5y5cvz3nnnZeVK1dm1apVeeihh7r2M3To0FxxxRV59tln\nc8oppxzo6wQAAPbRXt9u9MMf/jBLlizJjTfemClTpqSzs7N4fN26dTnppJN2+/yVK1cmSSZOnNi1\nbfjw4TnxxBPz1FNPJUlWrFiRwYMHF6ExduzY1NbWdq0BAAAOjr1GwmmnnZYnnngiU6ZM2eXj//qv\n/5pf//rXufjii/OBD3wg559/fr71rW91Pb5+/foMGTIk/fv3L543bNiwNDU1da05/vjjy8Gqq3Ps\nscd2rQEAAA6Ovb7daOjQobt97JVXXsnrr7+eF198Mddee23q6ury7W9/OzfddFOS5OKLL05bW1sG\nDhy403NramryyiuvJEna2tpSU1Oz05qBAwemra1tn18MAABw4Pb5wuVdOeKII3L//ffnpJNOylFH\nHZUkGTduXDZt2pRFixbl4osvTmdnZ6qqqnb5/B0XLe9pze62783atWvf0vPYu/b29iSOcU9yjHue\nY9z9nPmF7tXU1JTBgwdXeoyDxs/lnrfjGO+LA/qchMMOOyzjxo3rCoQdxo8fnw0bNmTLli2pra3d\n5dmAtra2DBo0KElSW1u7y9ud/uEaAADg4DigMwnr16/PihUrctlll6Vfv35d2994440MGDAgAwcO\nTH19fZqbm9PR0VGs2bhxY8aMGZMkqa+vzzPPPFPse/v27XnppZdy0UUXvaXZTj755Lf0PPZuR+E7\nxj3HMe55jnH3a25uTrKh0mNAr1FfX/+O+hnl53LPW7t2bbZs2bJPaw/oTMLLL7+cOXPm5Ic//GHX\nts7Oznz/+9/PGWeckeTNtx9t27Yty5cv71rT1NSU559/PuPGjetas3nz5qxZs6ZrzdNPP53W1tau\nNQAAwMFxQGcSxo4dm1GjRmX27NlpaWnJ4MGD89BDD+W5557L3/3d3yVJjj/++EyePDmzZs1Ka2tr\nBg0alIULF6ahoSGTJk1K8mYkjBw5MtOmTcsNN9yQrVu35tZbb82ECRN8RgIAABxk+xUJVVVVxYXE\n1dXVaWxszMKFC3PnnXfm9ddfz6mnnpr77ruv+OV+3rx5mTdvXhYsWJDt27fn7LPPzsyZM4t9NTY2\n5pZbbsmsWbPSr1+/TJo0KTNmzOiGlwgAAOyP/YqEq6++OldffXWx7YgjjsicOXP2+LwBAwZkzpw5\ne1x35JFH5vbbb9+fcQAAgB5wQNckAAAAvY9IAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAo\niAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAA\nCiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAA\ngIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQA\nAKAgEgAAgIJIAAAACiIBAAAo9K30AABvNy0tLVmzZk2lxzjkrF69utIjANBNRALAflqzZk0+P/sb\nqRtSX+lRDim/fm5Fjn7fuEqPAUA3EAkAb0HdkPocNezUSo9xSPnN5qZKjwBAN3FNAgAAUBAJAABA\nQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAA\nUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAACF/YqE\n5cuXZ/To0Tttb2xszIQJE3L66afnM5/5TF544YXi8Y6OjsydOzfjx4/P6NGjc80112TTpk3FmpaW\nltx0000ZO3ZszjzzzMycOTOtra1v4SUBAAAHYp8j4Wc/+1mmT5++0/a77747ixcvztSpU7Nw4cL8\n9re/zeWXX178gj979uw89thjuf766zNv3rysW7cuV155ZbZv3961Ztq0afnnf/7nzJkzJ1/84hfz\nxBNP5Prrrz/AlwcAAOyvvntb0NHRkaVLl+bOO+/MwIEDs3Xr1q7HWltbc++992batGmZMmVKkuSD\nH/xgJk6cmEceeSSXX355XnzxxTz22GO57bbbcsEFFyRJGhoaMnny5CxfvjznnXdeVq5cmVWrVuWh\nhx7KiBEjkiRDhw7NFVdckWeffTannHJKT7x2AABgF/Z6JuGHP/xhlixZkhtvvDFTpkxJZ2dn12Or\nV69Oe3t7zj333K5tdXV1GTNmTJ566qkkycqVK5MkEydO7FozfPjwnHjiiV1rVqxYkcGDB3cFQpKM\nHTs2tbW1XWsAAICDY6+RcNppp+WJJ57oOlPwh5qampIkxx9/fLF92LBhWb9+fZJk/fr1GTJkSPr3\n77/Tmh3PX79+/U77qK6uzrHHHtu1BgAAODj2+najoUOH7vax1tbW9OvXL337lrupqalJW1tbkqSt\nrS0DBw7c6bk1NTV55ZVXutbU1NTstGbgwIFd+wEAAA6OvUbCnnR2dqaqqmqXj1VXV3fLmt1t35u1\na9e+peexd+3t7Ukc457kGPe8AznGznACB0NTU1MGDx5c6TEOGv/t63k7jvG+OKDPSRg0aFA6Ojqy\nbdu2YntbW1sGDRqUJKmtrd3l2YA/XrOr253+4RoAAODgOKAzCcOHD09nZ2c2btyY4cOHd23fuHFj\nTjjhhCRJfX19mpub09HRkX79+hVrxowZ07XmmWeeKfa9ffv2vPTSS7nooove0mwnn3zyW3oee7ej\n8B3jnuMY97wDOcbNzc1JNnTzRACl+vr6d9R/B/y3r+etXbs2W7Zs2ae1B3QmYdSoUTnssMPy+OOP\nd21raWnJqlWrMm7cuCTJuHHjsm3btixfvrxrTVNTU55//vlizebNm7NmzZquNU8//XRaW1u71gAA\nAAfHAZ1JqKmpyZQpU3LHHXekuro6w4cPz+LFi1NXV5fLLrssyZt3Ppo8eXJmzZqV1tbWDBo0KAsX\nLkxDQ0MmTZqU5M1IGDlyZKZNm5YbbrghW7duza233poJEyb4jAQAADjI9isSqqqqdrqQ+Nprr011\ndXXuu+++tLW1ZfTo0Zk/f35qa2u71sybNy/z5s3LggULsn379px99tmZOXNmsa/GxsbccsstmTVr\nVvr165dJkyZlxowZB/jyAACA/bVfkXD11Vfn6quvLrb16dMn1113Xa677rrdPm/AgAGZM2dO5syZ\ns9s1Rx55ZG6//fb9GQcAAOgBB3RNAgAA0PuIBAAAoCASAACAgkgAAAAKIgEAACgc0OckAADQ/X7f\n8busXr3t9QZ6AAAVUklEQVS60mMcVE1NTUl2fKr97o0YMSKHH374QZjonU0kAAAcYra0vJzFj76c\nuqd+U+lRKmDDbh/5zeamNH75z3POOeccxHnemUQCAMAhqG5IfY4admqlx+AdyjUJAABAQSQAAAAF\nkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABA\nQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAA\nUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAAABREAgAAUBAJAABAQSQAAAAFkQAA\nABREAgAAUBAJAABAQSQAAACFvpUeADg0tbS0ZM2aNZUeo8c0NTUlSZqbm/f7uatXr+7maQDg0CIS\ngF1as2ZNPj/7G6kbUl/pUXrYhv1+xq+fW5Gj3zeuB2YBgEODSAB2q25IfY4admqlxzjk/GZzU6VH\nAIAe5ZoEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICC\nSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAArdEgmvvfZaGhoa\ndvr3hS98IUnS2dmZxsbGTJgwIaeffno+85nP5IUXXij20dHRkblz52b8+PEZPXp0rrnmmmzatKk7\nxgMAAPZD3+7YyS9/+cskyf3335+ampqu7UcccUSSZNGiRVmyZEmmT5+eY445Jo2Njbn88svzne98\nJ7W1tUmS2bNn54knnsiMGTMyYMCALFy4MFdeeWUeffTRVFc74QEAAAdLt0TCunXrMnjw4IwbN26n\nx1pbW3Pvvfdm2rRpmTJlSpLkgx/8YCZOnJhHHnkkl19+eV588cU89thjue2223LBBRckSRoaGjJ5\n8uQsX7485513XneMCQAA7INu+RP9unXr8v73v3+Xj61evTrt7e0599xzu7bV1dVlzJgxeeqpp5Ik\nK1euTJJMnDixa83w4cNz4okndq0BAAAOjm6LhPb29nziE5/IiBEj8qd/+qe59957kyRNTU1JkuOP\nP754zrBhw7J+/fokyfr16zNkyJD079+/WHPcccd1rQEAAA6OA3670bZt2/LCCy+kpqYm06dPz7HH\nHpsnn3wyt912W373u9+lb9++6devX/r2Lb9UTU1N2trakiRtbW0ZOHDgTvseOHBgXn755QMdEQAA\n2A8HHAlVVVVZsmRJjj766AwbNixJMmbMmGzZsiVf//rX8xd/8Repqqra5XN3XJDc2dm51zUAAMDB\nccCRUF1dnTFjxuy0ffz48fn7v//7DBgwIB0dHdm2bVv69OnT9XhbW1sGDRqUJKmtre06q/CH/nDN\n/lq7du1beh57197ensQx7kmHwjHe8VZBADiUNDU1ZfDgwZUe421px+8X++KA/0y/adOm/MM//ENe\nffXVYvsbb7yR5M2LlDs7O7Nx48bi8Y0bN+aEE05IktTX16e5uTkdHR27XQMAABwcB3wm4Y033sjs\n2bPT3t6eyy+/vGv79773vZxwwgk5//zzM3v27Dz++OOZOnVqkqSlpSWrVq3KNddckyQZN25ctm3b\nluXLl3fdArWpqSnPP/9815r9dfLJJx/YC2O3dvx12zHuOYfCMW5ubk6yoWJfHwB2pb6+3u8gb9Ha\ntWuzZcuWfVp7wJFw3HHH5cILL8wdd9yR6urqvOc978l3v/vdPP744/mbv/mbDBw4MFOmTOl6fPjw\n4Vm8eHHq6upy2WWXJXnzzkeTJ0/OrFmz0tramkGDBmXhwoVpaGjIpEmTDnREAABgP3TLh6nNnTs3\nixYtytKlS7N58+aceOKJueuuu7o+9+Daa69NdXV17rvvvrS1tWX06NGZP39+16ctJ8m8efMyb968\nLFiwINu3b8/ZZ5+dmTNn7vaCZgAAoGd0SyT0798/1113Xa677rpdPt6nT589Pp4kAwYMyJw5czJn\nzpzuGAkAAHiL3F8UAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAo\niAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAACiIBAAAoiAQAAKAgEgAAgIJIAAAA\nCiIBAAAoiAQAAKAgEgAAgELfSg8AldbS0pI1a9ZUeoxCU1NTkqS5ubliM6xevbpiXxsAqCyRwDve\nmjVr8vnZ30jdkPpKj7ILGyr2lX/93Ioc/b5xFfv6AEDliARIUjekPkcNO7XSYxxSfrO5qdIjAAAV\n4poEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAA\nAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIA\nAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACg0LfSAwAAwL74fcfvsnr16kqP\nccgaMWJEDj/88G7Zl0h4h2hpacmaNWu6ZV9NTU1Jkubm5m7ZX6X5YQMAbw9bWl7O4kdfTt1Tv6n0\nKIec32xuSuOX/zznnHNOt+xPJLxDrFmzJp+f/Y3UDanvxr1u6MZ9Vc6vn1uRo983rtJjAAD7oG5I\nfY4admqlx+j1RMI7iP9T7dpvNjdVegQAgEOKC5cBAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAA\nAAoiAQAAKIgEAACgIBIAAICCSAAAAAqHXCQ89NBDOf/88zNy5Mh84hOfyM9//vNKjwQAAO8oh1Qk\n/K//9b9y880356KLLspdd92VQYMG5b/+1/+ajRs3Vno0AAB4xzhkIqGzszN33XVXPv7xj+eqq67K\nf/pP/ymNjY1597vfnQceeKDS4wEAwDtG30oPsMO///u/56WXXsq5557bta1v376ZMGFCnnrqqf3e\n38ev+KvuHO9t76WN65Mjz6z0GAAAvA0cMpHQ1NSUJBk+fHixfdiwYdmwYUM6OztTVVW1z/vbcuSE\nbpzu7a9tU3X6V3oIAADeFg6Ztxu1trYmSWpqaortNTU12b59e7Zs2VKJsQAA4B3nkImEzs7OJNnt\n2YLq6kNmVAAA6NUOmbcbDRo0KEnS1taWI488smt7W1tb+vTpkwEDBuzX/tr/7R+7db63u983N+U3\n7e+p9BiHpLbXf13pEQ5JjsvuOTa75rjsnmOza47L7jk2u+a47N5vNjelqem4DB48eLdr2tvb93l/\nh0wk7LgWYcOGDTnuuOO6tm/YsCEnnHDCfu/v1lmf77bZ6O0+VOkBDlGOy+45NrvmuOyeY7Nrjsvu\nOTa75rjsTXe9Rf+QiYT6+vocffTRefzxx3P22WcnSbZu3Zr/83/+TyZOnLhf+zrjjDN6YkQAAHhH\nOGQioaqqKp/97Gdzyy23pK6uLqNHj87/+B//Iy0tLbn88ssrPR4AALxjVHXuuGL4EHH//ffnb//2\nb/Paa6/l5JNPzk033ZSRI0dWeiwAAHjHOOQiAQAAqCz3FQUAAAoiAQAAKIgEAACgIBIAAICCSAAA\nAAoiAQAAKPTKSFi+fHlGjx5d6TF6ne3bt+f+++/PBRdckFGjRuXDH/5wHnzwwUqP1at0dHTk9ttv\nz8SJEzNq1Kh8+tOfzrPPPlvpsXqtjo6OXHDBBZkxY0alR+l1XnvttTQ0NOz07wtf+EKlR+tVVqxY\nkT/7sz/LyJEjc+655+auu+7K9u3bKz1Wr/H000/v8vt4x79f//rXlR6xV+js7MwDDzyQD33oQxk1\nalQ+9rGPZeXKlZUeq1dpb2/Pf//v/z3/8T/+x4waNSqXX355/uVf/mWPzzlkPnG5u/zsZz/L9OnT\nKz1Gr7Ro0aIsWbIkV111VUaOHJmf/OQnmTt3btrb2zN16tRKj9crzJs3L8uWLcv06dMzfPjwLF26\nNJ/61KeybNmyHHPMMZUer9e5++67s379+px++umVHqXX+eUvf5nkzQ/IrKmp6dp+xBFHVGqkXuen\nP/1pPvvZz+YjH/lIrr/++vziF7/IHXfckaqqqlx99dWVHq9XOPXUU/PQQw8V2373u9/lmmuuyQc+\n8IEcffTRFZqsd1m6dGm++tWv5gtf+EJOO+20PPLII5k6dWoefvjhnHzyyZUer1eYNm1afvKTn+Sq\nq67KBz7wgSxfvjx//ud/ngcffDCnnnrqLp/TayKho6MjS5cuzZ133pmBAwdm69atlR6pV9m2bVse\neOCBTJ06NZ/73OeSJGeddVZeffXV3HfffSKhG/z2t7/Nww8/nOuvvz6f+MQnkiSjR4/O2LFj89hj\nj+Xzn/98hSfsXZ599tl84xvfyLvf/e5Kj9IrrVu3LoMHD864ceMqPUqvddttt2X8+PGZN29ekmTs\n2LF5/fXXs2rVqgpP1nvU1tZmxIgRxbavfOUrqa6uzle/+tUKTdX7fPOb38xHPvKRXHnllUne/F7+\n2c9+lkceeSSzZs2q8HRvf7/4xS/yox/9KDfffHPX7xfjxo3Lyy+/nK9+9at54IEHdvm8XvN2ox/+\n8IdZsmRJbrzxxkyZMiU+SLp7tbW15ZJLLsn5559fbK+vr8+rr76a3/3udxWarPcYOHBgHnnkkVx6\n6aVd2/r06ZOqqirR281+//vf54tf/GKmTp2aoUOHVnqcXmndunV5//vfX+kxeq1XX301zzzzTD7+\n8Y8X26+77rr87d/+bYWm6v2ef/75/M//+T/z3/7bf/MHhm7U2tpanHGsrq5ObW1tWlpaKjhV79HU\n1JQkOeecc4rto0ePzj//8z+no6Njl8/rNZFw2mmn5YknnsiUKVMqPUqvVFdXl5kzZ6ahoaHY/uST\nT+boo49O//79KzRZ79GnT580NDSkrq4unZ2d2bBhQ774xS+mqqoqH/3oRys9Xq+yZMmSbNu2LVde\neaU/KPSQdevWpb29PZ/4xCcyYsSI/Omf/mnuvffeSo/Va6xbty6dnZ3p379//uIv/iIjRozI2Wef\nnbvvvtv3dA+6/fbbc8IJJ+RjH/tYpUfpVT760Y/msccey4oVK/Lb3/42S5cuzfPPP58Pf/jDlR6t\nV/gP/+E/JEleeumlYvvGjRuzbdu23V5b02vebuSvgQffww8/nBUrVjgV2AMWLVqUu+++O0nyhS98\nIfX19ZUdqBf5t3/7t3zta1/L0qVL8653vavS4/RK27ZtywsvvJCamppMnz49xx57bJ588sncdttt\n+d3vfperrrqq0iO+7b322mtJkhtvvDEf+chH8pnPfCarVq1KY2NjDjvssHz2s5+t8IS9z4YNG/Lk\nk0/mlltuqfQovc4111yTdevW5Yorruja9ld/9VeZOHFiBafqPUaOHJn3vOc9ufnmmzNv3ryccMIJ\n+cEPfpB//Md/TFVVVdrb23f5vF4TCRxcy5Yty80335zJkyfnk5/8ZKXH6XXOO++8nHXWWVm5cmUW\nLVqUjo4Od4XpBtu3b8+XvvSlXHbZZRk5cmSSpKqqqsJT9T5VVVVZsmRJjj766AwbNixJMmbMmGzZ\nsiVf//rX89nPfjb9+vWr8JRvbzvegnjOOed03azjzDPPzGuvvZbGxsZMnTrV93Y3e/jhh3P44Yc7\ns9sDpk+fnmeeeSY333xz3vve9+bHP/5x7rrrrtTW1vodoxu8613vyl133ZXp06d3nQU75ZRT8pd/\n+Ze59dZbd/tuEJHAfrv//vszf/78/Of//J+zYMGCSo/TK+14L/cHP/jBtLW15d57783VV1+dPn36\nVHiyt7dvfOMbefnll7NkyZL8/ve/T/Lmrfc6Ozuzbds2x7ebVFdXZ8yYMTttHz9+fP7+7/8+L774\nYk488cQKTNZ77Hj/9h+/x3jcuHF58MEHs3Hjxhx33HGVGK3X+qd/+qdMmjTJGchu9i//8i/5zne+\nkzvuuCMf+tCHkrz5R4Vt27ZlwYIFufTSSzNgwIAKT/n29973vjePPvpoXnnllXR0dOS4447ruo39\n4Ycfvsvn9JprEjg4Fi5cmFtvvTUXX3xx7rzzzvTtqzO7S3Nzc775zW+mra2t2N7Q0JCOjo68/vrr\nFZqs9/inf/qnvPzyyxkzZkw+8IEP5AMf+EDWrVuXb33rWzn11FN3er8mb82mTZvyD//wD3n11VeL\n7W+88UaSuOCzGxx//PFJstNNDXbEr7MI3eull17KCy+8kPPOO6/So/Q6//7v/54kO92KevTo0Wlv\nb8+vfvWrSozVq7zxxhtZtmxZNm3alKFDh3b9AWHdunUZOnTobn8miwT22dKlS3PPPffk05/+dObN\nm5fqat8+3amlpSVf+tKX8r3vfa/Y/uMf/ziDBw/OUUcdVaHJeo85c+bkm9/8Zte/Rx55JPX19Zk4\ncWK++c1vZsiQIZUesVd44403Mnv27CxbtqzY/r3vfS8nnHCC7+Vu8L73vS9Dhw7N//7f/7vY/oMf\n/CBDhw7tepsX3WPNmjVJdv5FlgO34xfWn/70p8X21atXp2/fvl0X3fLW9enTJzfffHO+/e1vd237\nf//v/+W73/3uHq/78Gdg9smmTZuyYMGCnHTSSbnwwgvz85//vHj8tNNO81aNA/Te9743559/fm69\n9dZs3bo1w4YNy/e///0sW7as6z7oHJgTTjhhp22HHXZYjjjiiN1+mAz777jjjsuFF16YO+64I9XV\n1XnPe96T7373u3n88cfzN3/zN5Uer1eoqqrKX/3VX+Wmm27KzTffnA996EP5v//3/+Zb3/pWvvzl\nL1d6vF7nueeey7vf/e7U1dVVepReZ+TIkTn77LPz5S9/Oa+//nre8573ZNWqVfn617+eT33qU6mt\nra30iG97ffv2zcc+9rF87Wtfy5FHHpkjjjgif/3Xf51+/frt8TOYemUkVFVVOdXazX70ox9l69at\nee6553a6L3dVVVVWrFjhk1S7wfz583P33Xfna1/7WjZv3pz3ve99ufPOO3f6fAq6j58VPWPu3LlZ\ntGhRli5dms2bN+fEE0/MXXfd5W4l3ejiiy/Ou971rixevDiPPvpojj766MyZMyd/9md/VunRep1X\nX31VIPSgxsbGNDY2ZunSpdm0aVOOP/74zJo1a6ffN3jrrr322iTpusvcmDFj8td//dd7vDtoVacb\nKgMAAH/Am8oBAICCSAAAAAoiAQAAKIgEAACgIBIAAICCSAAAAAoiAQAAKIgEAACgIBIAAIDC/we/\ns6jw+g0OGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10abb4090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(statsdf.user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin analysis by using PCA to reduce the number of dimensions features in the data. Our variation cutoff will be 5%. So if variation falls below 5% after a certain component, we will remove all remaining dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1500)\n",
    "\n",
    "new_X = pca.fit_transform(Xsampleddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950989475389\n"
     ]
    }
   ],
   "source": [
    "pca.explained_variance_ratio_\n",
    "print pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdf = pd.DataFrame()\n",
    "\n",
    "for i in range(pca.explained_variance_ratio_.shape[0]):\n",
    "    Xdf[\"pc%i\" % (i+1)] = new_X[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>pc11</th>\n",
       "      <th>pc12</th>\n",
       "      <th>pc13</th>\n",
       "      <th>pc14</th>\n",
       "      <th>pc15</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>pc25</th>\n",
       "      <th>pc26</th>\n",
       "      <th>pc27</th>\n",
       "      <th>pc28</th>\n",
       "      <th>pc29</th>\n",
       "      <th>pc30</th>\n",
       "      <th>pc31</th>\n",
       "      <th>pc32</th>\n",
       "      <th>pc33</th>\n",
       "      <th>pc34</th>\n",
       "      <th>pc35</th>\n",
       "      <th>pc36</th>\n",
       "      <th>pc37</th>\n",
       "      <th>pc38</th>\n",
       "      <th>pc39</th>\n",
       "      <th>pc40</th>\n",
       "      <th>pc41</th>\n",
       "      <th>pc42</th>\n",
       "      <th>pc43</th>\n",
       "      <th>pc44</th>\n",
       "      <th>pc45</th>\n",
       "      <th>pc46</th>\n",
       "      <th>pc47</th>\n",
       "      <th>pc48</th>\n",
       "      <th>pc49</th>\n",
       "      <th>pc50</th>\n",
       "      <th>...</th>\n",
       "      <th>pc1451</th>\n",
       "      <th>pc1452</th>\n",
       "      <th>pc1453</th>\n",
       "      <th>pc1454</th>\n",
       "      <th>pc1455</th>\n",
       "      <th>pc1456</th>\n",
       "      <th>pc1457</th>\n",
       "      <th>pc1458</th>\n",
       "      <th>pc1459</th>\n",
       "      <th>pc1460</th>\n",
       "      <th>pc1461</th>\n",
       "      <th>pc1462</th>\n",
       "      <th>pc1463</th>\n",
       "      <th>pc1464</th>\n",
       "      <th>pc1465</th>\n",
       "      <th>pc1466</th>\n",
       "      <th>pc1467</th>\n",
       "      <th>pc1468</th>\n",
       "      <th>pc1469</th>\n",
       "      <th>pc1470</th>\n",
       "      <th>pc1471</th>\n",
       "      <th>pc1472</th>\n",
       "      <th>pc1473</th>\n",
       "      <th>pc1474</th>\n",
       "      <th>pc1475</th>\n",
       "      <th>pc1476</th>\n",
       "      <th>pc1477</th>\n",
       "      <th>pc1478</th>\n",
       "      <th>pc1479</th>\n",
       "      <th>pc1480</th>\n",
       "      <th>pc1481</th>\n",
       "      <th>pc1482</th>\n",
       "      <th>pc1483</th>\n",
       "      <th>pc1484</th>\n",
       "      <th>pc1485</th>\n",
       "      <th>pc1486</th>\n",
       "      <th>pc1487</th>\n",
       "      <th>pc1488</th>\n",
       "      <th>pc1489</th>\n",
       "      <th>pc1490</th>\n",
       "      <th>pc1491</th>\n",
       "      <th>pc1492</th>\n",
       "      <th>pc1493</th>\n",
       "      <th>pc1494</th>\n",
       "      <th>pc1495</th>\n",
       "      <th>pc1496</th>\n",
       "      <th>pc1497</th>\n",
       "      <th>pc1498</th>\n",
       "      <th>pc1499</th>\n",
       "      <th>pc1500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066350</td>\n",
       "      <td>-0.670093</td>\n",
       "      <td>-0.050836</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>-1.125600</td>\n",
       "      <td>-0.056040</td>\n",
       "      <td>-0.105434</td>\n",
       "      <td>0.190272</td>\n",
       "      <td>0.538619</td>\n",
       "      <td>-0.195652</td>\n",
       "      <td>-0.399023</td>\n",
       "      <td>-0.164460</td>\n",
       "      <td>-0.293033</td>\n",
       "      <td>-0.027973</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.037682</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>-0.011806</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.056476</td>\n",
       "      <td>-0.053256</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>-0.100227</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.164204</td>\n",
       "      <td>-0.069500</td>\n",
       "      <td>-0.098806</td>\n",
       "      <td>0.166479</td>\n",
       "      <td>-0.150137</td>\n",
       "      <td>0.079788</td>\n",
       "      <td>-1.153106</td>\n",
       "      <td>-0.104587</td>\n",
       "      <td>-0.621643</td>\n",
       "      <td>-0.072449</td>\n",
       "      <td>0.047920</td>\n",
       "      <td>-0.040244</td>\n",
       "      <td>-0.065587</td>\n",
       "      <td>0.058357</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.021478</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>0.076853</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>-0.002168</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.001389</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.001358</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>5.545358e-15</td>\n",
       "      <td>-1.071335e-15</td>\n",
       "      <td>8.011229e-17</td>\n",
       "      <td>2.192823e-15</td>\n",
       "      <td>-2.000105e-15</td>\n",
       "      <td>3.678057e-15</td>\n",
       "      <td>4.806914e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.560812</td>\n",
       "      <td>0.531123</td>\n",
       "      <td>0.382659</td>\n",
       "      <td>0.333944</td>\n",
       "      <td>-0.439023</td>\n",
       "      <td>0.241006</td>\n",
       "      <td>-0.316783</td>\n",
       "      <td>0.065685</td>\n",
       "      <td>0.135553</td>\n",
       "      <td>-0.021532</td>\n",
       "      <td>-0.771417</td>\n",
       "      <td>-0.326313</td>\n",
       "      <td>-0.164382</td>\n",
       "      <td>-0.026190</td>\n",
       "      <td>0.103695</td>\n",
       "      <td>0.084151</td>\n",
       "      <td>-0.096116</td>\n",
       "      <td>0.168581</td>\n",
       "      <td>0.021410</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>-0.020731</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>-0.034160</td>\n",
       "      <td>0.054860</td>\n",
       "      <td>-0.053168</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>-0.023070</td>\n",
       "      <td>0.023686</td>\n",
       "      <td>-0.010562</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>-0.055836</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>-0.053014</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>-0.028106</td>\n",
       "      <td>-0.033452</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>-0.026669</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>-0.029366</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>-0.025068</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>-0.001926</td>\n",
       "      <td>-0.002465</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>-0.001539</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.001807</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-4.630789e-15</td>\n",
       "      <td>-8.194638e-15</td>\n",
       "      <td>1.200081e-15</td>\n",
       "      <td>2.935721e-15</td>\n",
       "      <td>3.506154e-15</td>\n",
       "      <td>1.522058e-15</td>\n",
       "      <td>-5.373756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610763</td>\n",
       "      <td>-0.315403</td>\n",
       "      <td>-0.474722</td>\n",
       "      <td>-0.212557</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>0.524099</td>\n",
       "      <td>-0.173022</td>\n",
       "      <td>-0.202003</td>\n",
       "      <td>-0.186362</td>\n",
       "      <td>-0.111612</td>\n",
       "      <td>0.462814</td>\n",
       "      <td>-0.012471</td>\n",
       "      <td>-0.039386</td>\n",
       "      <td>-0.038874</td>\n",
       "      <td>-0.399794</td>\n",
       "      <td>0.047593</td>\n",
       "      <td>-0.805383</td>\n",
       "      <td>0.360135</td>\n",
       "      <td>-0.076638</td>\n",
       "      <td>-0.156924</td>\n",
       "      <td>0.414043</td>\n",
       "      <td>0.139779</td>\n",
       "      <td>-0.321184</td>\n",
       "      <td>0.235991</td>\n",
       "      <td>0.442186</td>\n",
       "      <td>0.351778</td>\n",
       "      <td>0.342874</td>\n",
       "      <td>0.189957</td>\n",
       "      <td>0.033711</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.737087</td>\n",
       "      <td>0.313009</td>\n",
       "      <td>-0.201215</td>\n",
       "      <td>0.233734</td>\n",
       "      <td>-0.029612</td>\n",
       "      <td>0.108084</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>-0.022965</td>\n",
       "      <td>0.065336</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>0.037796</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>-0.055087</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>-0.007032</td>\n",
       "      <td>-0.014146</td>\n",
       "      <td>-0.002670</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>-0.008668</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.005786</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.039011</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>-0.080612</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>-0.010619</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.042320</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>-0.019962</td>\n",
       "      <td>0.022043</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>-0.023286</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>-0.012916</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.020375</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>-0.008840</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>6.705348e-15</td>\n",
       "      <td>8.061745e-15</td>\n",
       "      <td>4.665459e-15</td>\n",
       "      <td>-1.428342e-14</td>\n",
       "      <td>4.616225e-15</td>\n",
       "      <td>-2.493985e-14</td>\n",
       "      <td>-2.236853e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117680</td>\n",
       "      <td>0.499039</td>\n",
       "      <td>-0.666343</td>\n",
       "      <td>0.104795</td>\n",
       "      <td>0.429531</td>\n",
       "      <td>-0.598048</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>-0.014096</td>\n",
       "      <td>0.173909</td>\n",
       "      <td>-0.139098</td>\n",
       "      <td>-0.152528</td>\n",
       "      <td>0.097668</td>\n",
       "      <td>0.120513</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.121165</td>\n",
       "      <td>-0.072110</td>\n",
       "      <td>-0.102072</td>\n",
       "      <td>-0.034262</td>\n",
       "      <td>0.052635</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.080861</td>\n",
       "      <td>0.054988</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>-0.011362</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>-0.024669</td>\n",
       "      <td>-0.061805</td>\n",
       "      <td>-0.060235</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>-0.009676</td>\n",
       "      <td>-0.018192</td>\n",
       "      <td>0.028999</td>\n",
       "      <td>-0.019510</td>\n",
       "      <td>0.033466</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>-0.011181</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>-0.021586</td>\n",
       "      <td>-0.018842</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>-0.009931</td>\n",
       "      <td>-0.021578</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>-0.020722</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001730</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>-0.001535</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.004383</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>-0.005182</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-0.003562</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.002910</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.003514</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.003416</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>-0.003304</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-4.104184e-15</td>\n",
       "      <td>-9.534357e-16</td>\n",
       "      <td>-2.968783e-15</td>\n",
       "      <td>2.023738e-15</td>\n",
       "      <td>1.020067e-16</td>\n",
       "      <td>-1.431353e-14</td>\n",
       "      <td>-1.475223e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.053905</td>\n",
       "      <td>-0.729001</td>\n",
       "      <td>0.166426</td>\n",
       "      <td>0.743913</td>\n",
       "      <td>-0.268818</td>\n",
       "      <td>-0.016824</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>0.082453</td>\n",
       "      <td>-0.181618</td>\n",
       "      <td>0.188368</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>0.317115</td>\n",
       "      <td>0.411104</td>\n",
       "      <td>-0.048532</td>\n",
       "      <td>0.055576</td>\n",
       "      <td>-0.089072</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>-0.017144</td>\n",
       "      <td>0.061743</td>\n",
       "      <td>-0.026660</td>\n",
       "      <td>0.049179</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>-0.020411</td>\n",
       "      <td>-0.073979</td>\n",
       "      <td>0.026992</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>-0.031789</td>\n",
       "      <td>-0.016775</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.009325</td>\n",
       "      <td>0.049228</td>\n",
       "      <td>-0.052647</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.049261</td>\n",
       "      <td>-0.212828</td>\n",
       "      <td>0.071786</td>\n",
       "      <td>-0.082025</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.005113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>-1.094832e-15</td>\n",
       "      <td>-1.232665e-15</td>\n",
       "      <td>4.200030e-16</td>\n",
       "      <td>6.413104e-16</td>\n",
       "      <td>1.452666e-16</td>\n",
       "      <td>3.434471e-16</td>\n",
       "      <td>1.907441e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6       pc7       pc8       pc9      pc10      pc11      pc12      pc13      pc14      pc15      pc16      pc17      pc18      pc19      pc20      pc21      pc22      pc23      pc24      pc25      pc26      pc27      pc28      pc29      pc30      pc31      pc32      pc33      pc34      pc35      pc36      pc37      pc38      pc39      pc40      pc41      pc42      pc43      pc44      pc45      pc46      pc47      pc48      pc49  \\\n",
       "0 -0.066350 -0.670093 -0.050836  0.078633 -1.125600 -0.056040 -0.105434  0.190272  0.538619 -0.195652 -0.399023 -0.164460 -0.293033 -0.027973  0.122600  0.037682  0.003890 -0.031325 -0.011806  0.046461 -0.056476 -0.053256  0.008578  0.044745 -0.100227  0.071823  0.046617  0.066691  0.062903  0.000380  0.164204 -0.069500 -0.098806  0.166479 -0.150137  0.079788 -1.153106 -0.104587 -0.621643 -0.072449  0.047920 -0.040244 -0.065587  0.058357  0.000321 -0.000242 -0.021478 -0.027888  0.076853   \n",
       "1 -0.560812  0.531123  0.382659  0.333944 -0.439023  0.241006 -0.316783  0.065685  0.135553 -0.021532 -0.771417 -0.326313 -0.164382 -0.026190  0.103695  0.084151 -0.096116  0.168581  0.021410 -0.009517 -0.020731  0.033012 -0.034160  0.054860 -0.053168  0.011908 -0.023070  0.023686 -0.010562  0.020057 -0.055836  0.003963 -0.053014  0.096105 -0.028106 -0.033452  0.033938  0.007513 -0.026669  0.034174 -0.029366  0.021898  0.011461 -0.025068 -0.001814  0.005328  0.018447  0.001233  0.018085   \n",
       "2  0.610763 -0.315403 -0.474722 -0.212557  0.035915  0.524099 -0.173022 -0.202003 -0.186362 -0.111612  0.462814 -0.012471 -0.039386 -0.038874 -0.399794  0.047593 -0.805383  0.360135 -0.076638 -0.156924  0.414043  0.139779 -0.321184  0.235991  0.442186  0.351778  0.342874  0.189957  0.033711  0.017275  0.737087  0.313009 -0.201215  0.233734 -0.029612  0.108084  0.090686 -0.022965  0.065336  0.012187 -0.055115  0.037796  0.054085 -0.055087  0.015385  0.008298  0.013550  0.009909 -0.006662   \n",
       "3  0.117680  0.499039 -0.666343  0.104795  0.429531 -0.598048  0.014088 -0.014096  0.173909 -0.139098 -0.152528  0.097668  0.120513 -0.009330  0.121165 -0.072110 -0.102072 -0.034262  0.052635  0.009866  0.080861  0.054988  0.001523 -0.011362 -0.001016  0.009547 -0.024669 -0.061805 -0.060235  0.011753 -0.009676 -0.018192  0.028999 -0.019510  0.033466  0.009968 -0.011181  0.009403 -0.021586 -0.018842  0.026755 -0.009931 -0.021578  0.037902  0.011662  0.012444  0.001497 -0.020722  0.019469   \n",
       "4 -0.053905 -0.729001  0.166426  0.743913 -0.268818 -0.016824 -0.002326  0.082453 -0.181618  0.188368  0.028115  0.317115  0.411104 -0.048532  0.055576 -0.089072 -0.022603 -0.017144  0.061743 -0.026660  0.049179 -0.000930  0.002658  0.017294  0.008629  0.002599  0.006455 -0.020411 -0.073979  0.026992 -0.037640  0.019390 -0.031789 -0.016775  0.018845 -0.003493  0.005769  0.022092 -0.009325  0.049228 -0.052647  0.007348  0.022931  0.008130  0.049261 -0.212828  0.071786 -0.082025  0.030492   \n",
       "\n",
       "       pc50      ...         pc1451    pc1452    pc1453    pc1454    pc1455    pc1456    pc1457    pc1458    pc1459    pc1460    pc1461    pc1462    pc1463    pc1464    pc1465    pc1466    pc1467    pc1468    pc1469    pc1470    pc1471    pc1472    pc1473    pc1474    pc1475    pc1476    pc1477    pc1478    pc1479    pc1480    pc1481    pc1482    pc1483    pc1484    pc1485    pc1486    pc1487    pc1488    pc1489    pc1490    pc1491    pc1492    pc1493        pc1494        pc1495        pc1496  \\\n",
       "0  0.009436      ...      -0.000438 -0.002407  0.001025  0.002078  0.000568 -0.000128  0.000520 -0.002168  0.002026 -0.001497 -0.002197 -0.001142  0.000665  0.000840 -0.000200  0.001133  0.001909 -0.000977  0.000437 -0.001389 -0.001871 -0.000345  0.001306  0.000659  0.001392 -0.001358 -0.000818  0.001093 -0.000189  0.000809 -0.000589  0.000197 -0.000129  0.000094  0.000048 -0.001028 -0.000985 -0.000508  0.000316 -0.000454  0.000286 -0.000285 -0.000136  5.545358e-15 -1.071335e-15  8.011229e-17   \n",
       "1  0.008192      ...       0.006794  0.006914  0.005465 -0.000749  0.003412  0.007277  0.002803  0.003248  0.006883 -0.002268  0.000807 -0.000491  0.003035  0.006386  0.000034 -0.000559  0.003034 -0.003492  0.000237 -0.001926 -0.002465  0.000450 -0.001249  0.002407  0.000779 -0.004617  0.000620 -0.003264 -0.001933  0.001040  0.001819  0.001321 -0.001332  0.001044 -0.001357  0.001890 -0.001539  0.001206 -0.000218 -0.001807 -0.000571 -0.001234 -0.000651 -4.630789e-15 -8.194638e-15  1.200081e-15   \n",
       "2  0.008863      ...       0.009580  0.008613 -0.001274 -0.008282  0.000454  0.004485 -0.007032 -0.014146 -0.002670  0.008665  0.017603 -0.008668  0.005087 -0.000927 -0.005786  0.025804  0.009820  0.039011  0.012167 -0.080612 -0.005553  0.001007  0.007712  0.004880 -0.010619  0.026855  0.042320  0.013477 -0.019962  0.022043  0.009657 -0.023286  0.036905  0.011638 -0.012916  0.004692 -0.004997 -0.002481  0.020375  0.002992 -0.008840  0.002359  0.005339  6.705348e-15  8.061745e-15  4.665459e-15   \n",
       "3  0.012752      ...      -0.001730 -0.001033  0.002889 -0.003900  0.004070  0.002696 -0.001535 -0.002978 -0.000174 -0.000019 -0.004383  0.006234 -0.005182 -0.002339  0.003972 -0.001523  0.000504  0.000863 -0.003562  0.001162 -0.002910 -0.003583  0.001927  0.003377 -0.000338 -0.003514  0.000132  0.000465 -0.003416  0.002678 -0.003304 -0.000115 -0.003947  0.000188 -0.001751  0.001631 -0.000060  0.000084 -0.001118  0.000464  0.001273 -0.000803  0.001313 -4.104184e-15 -9.534357e-16 -2.968783e-15   \n",
       "4 -0.005113      ...       0.000934 -0.000114  0.000698  0.000115 -0.002001 -0.000077 -0.000651  0.000120 -0.001042 -0.000417  0.000247 -0.000417  0.000597  0.000014  0.001343 -0.000412 -0.000944 -0.000890 -0.000590  0.000854 -0.000548 -0.000477 -0.000300 -0.000246 -0.000271 -0.000182  0.001524 -0.001093 -0.000353 -0.000046 -0.000475 -0.000136 -0.000060 -0.000405 -0.000106  0.000257 -0.000023 -0.000208 -0.000117 -0.000234  0.000215 -0.000020  0.000118 -1.094832e-15 -1.232665e-15  4.200030e-16   \n",
       "\n",
       "         pc1497        pc1498        pc1499        pc1500  \n",
       "0  2.192823e-15 -2.000105e-15  3.678057e-15  4.806914e-17  \n",
       "1  2.935721e-15  3.506154e-15  1.522058e-15 -5.373756e-16  \n",
       "2 -1.428342e-14  4.616225e-15 -2.493985e-14 -2.236853e-15  \n",
       "3  2.023738e-15  1.020067e-16 -1.431353e-14 -1.475223e-15  \n",
       "4  6.413104e-16  1.452666e-16  3.434471e-16  1.907441e-16  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a data set with reduced dimension. Now, the features are the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3. Train Test Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split our data set into train and test sets. Our data set consists of 10,000 titles. We want training and testing data in the ratio 3:1. So, the size of each set will be 4,500 and 1,500, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xdf.values, ratingsdf_sampled['reception'].values, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4. Baseline Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate a baseline accuracy by assuming that all the predictions were well-received. This gives us a baseline of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.7716\n"
     ]
    }
   ],
   "source": [
    "baseline  = sum(ytest)*1./len(ytest)\n",
    "print 'Baseline Accuracy: %0.4f' % baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our classifier to to worthwhile pursuing, the classifier's accuracy should be better than the baseline. This is what we will explore in the next few sections using logistic regression and KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.5. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we perform a linear regression of user ratings on the dummy variables for each location and genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to study the effects of locations and genre on category. Since we have reduced locations and genres to principal components, we will perform a logistic regression of film reception on the principal components. We denote $ Y = $ Reception and $PC_c$ = Dummy Variable for principal component $c$.\n",
    "\n",
    "Our regression equation will take the following form:\n",
    "\n",
    "$$ P(Y_i=1) = F(\\beta_0 + \\delta_1 PC_{1i} + \\delta_2 PC_{2i} + ... + \\delta_C PC_{Ci})$$\n",
    "\n",
    "where $\\beta_0$ is the intercept parameter, $\\delta_c$ are the slope parameters for the principal components and $F$ is the logistic function defined as:\n",
    "\n",
    "$$ F(x) = \\frac{e^x}{e^x + 1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After estimating the coefficients, we apply the coefficient estimates on the test set. Then, we compare the accuracy of predicting $Y$ on both the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we first find the best paramater C for the logistic regression from the training set using 5-folds cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we perform a regression using all the features of locations and genres as regressors to study the significance of each feature. To do so, we split statsdf into the same training and test data. We fit the model with our training data and test test on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain2, Xtest2, ytrain2, ytest2 = train_test_split(Xsampleddf, ratingsdf_sampled['reception'].values, train_size=0.75, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0),\n",
       " {'C': 0.1},\n",
       " 0.77893333333333337,\n",
       " [mean: 0.76507, std: 0.00021, params: {'C': 0.0001},\n",
       "  mean: 0.76507, std: 0.00021, params: {'C': 0.001},\n",
       "  mean: 0.77893, std: 0.00646, params: {'C': 0.1},\n",
       "  mean: 0.77680, std: 0.00652, params: {'C': 1},\n",
       "  mean: 0.75720, std: 0.00695, params: {'C': 10},\n",
       "  mean: 0.74413, std: 0.00556, params: {'C': 100}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression()\n",
    "parameters = {\"C\": [0.0001, 0.001, 0.1, 1, 10, 100]}\n",
    "fitmodel = GridSearchCV(clf, param_grid=parameters, cv=5, scoring=\"accuracy\")\n",
    "fitmodel.fit(Xtrain2, ytrain2)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we perform the logistic regression using the best parameter C, fit our training set and then test on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.7912\n",
      "Accuracy on test data:     0.7892\n"
     ]
    }
   ],
   "source": [
    "clflog=LogisticRegression(C=fitmodel.best_params_['C'])\n",
    "clflog.fit(Xtrain2, ytrain2)\n",
    "train_accuracy = clflog.score(Xtrain2,ytrain2)\n",
    "test_accuracy=clflog.score(Xtest2,ytest2)\n",
    "print \"Accuracy on training data: %0.4f\" % (train_accuracy)\n",
    "print \"Accuracy on test data:     %0.4f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.5. K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the non-parametrised kNN classification with distance defined by the principal components. We train the data and use cross-validation to find the optimal K. Then, we look at the accuracy of prediction on the test data, comparing it with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for performing kNN classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf= KNeighborsClassifier(nbrs)\n",
    "clf=clf.fit(Xtrain, ytrain)\n",
    "accuracy = clf.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to find the optimal k neighbours from training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid={\"n_neighbors\": range(1,40,2)}, cv=5)\n",
    "gs.fit(Xtrain, ytrain)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply to the test set and compare the accuracy with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfknn=KNeighborsClassifier(n_neighbors=gs.best_params_)\n",
    "clfknn.fit(Xtrain, ytrain)\n",
    "clfknn.score(Xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax=plt.gca()\n",
    "points_plot(ax, Xtrain, Xtest, ytrain, ytest, clfknn.fit(Xtrain, ytrain), alpha=0.3, psize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
