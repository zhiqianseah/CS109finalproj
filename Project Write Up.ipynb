{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analysis of Film Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Table of Contents\n",
    "* [Analysis of Film Locations](#Analysis-of-Film-Locations)\n",
    "    * [1. Overview](#1.-Overview)\n",
    "\t* [2. Data Acquisition & Management](#2.-Data-Acquisition-&-Management)\n",
    "        * [2.1. Approach 1](#2.1.-Approach-1)\n",
    "        * [2.2. Approach 2](#2.2.-Approach-2)\n",
    "    * [3. Linear Regression](#3.-Linear-Regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we study the relationship between film locations and other factors like ratings and genres. Data will be scraped from [IMDB](http://www.imdb.com). Statistical and machine learning analytical tools will be used in our study. Visualisation of results will be done via graphical plots and Tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Data Acquisition & Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first scrape the data from IMDB which gives us information about each movie such as budget, country, critic ratings, duration, genre, gross earnings, language, location, name, opening weekend earnings, release dates, url, user ratings, user ratings count and year. We wanted a data set of 12,000 titles and focused our analysis on the most recent titles. As an example, there were 8,997 titles in 2014. However, some of these were missing location data. Hence, we scraped as far back as we could to obtain the desired data set size.\n",
    "\n",
    "The ratings and genres of each title does not require much cleaning. However, because the locations of each title is user-contributed, it required much cleaning. For example, there were many cases of multiple entries, albeit differently worded. In some cases, locations were specified to the street while others merely stated the country. Our first task was to clean the locations variable.\n",
    "\n",
    "In cleaning up the variable \"locations\", there are two approaches for consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1. Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we restrict \"locations\" to cities; in particular, cities belonging to top filming locations. In this case, the top $T$ filming locations will be identified by the most frequent filming locations in our data set. So, we split each \"locations\" by commas into phrases and add them to a set. Then, we remove elements of this set which are not cities, as defined by [Wikipedia](https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/country:_A-B). Then, we find the $T$ most frequent elements from our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2. Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the entries of \"locations\" by commas and treat each unique phrase as a distinct location. For example, suppose we have \"Newbury Street, Boston, USA, Boston, USA\". We split it into \"Newbury Street\", \"Boston\" and \"USA\". Later on, in our analysis, we treat each of these as distinct locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
