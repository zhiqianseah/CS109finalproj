{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "# The \"requests\" library makes working with HTTP requests easier\n",
    "# than the built-in urllib libraries.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "YEAR_START = 2014\n",
    "YEAR_END = 2014\n",
    "TYPE = \"feature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here we access the webpage and download the content using requests\n",
    "page=requests.get(\"http://www.imdb.com/search/title?at=0&sort=alpha&title_type=\"+TYPE+\"&year=\"+str(YEAR_START)+\",\"+str(YEAR_END))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8997\n"
     ]
    }
   ],
   "source": [
    "#First, we get the number of results for this particular year\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "NumResults = soup.find(\"div\", attrs={\"class\": \"leftright\"}).find_all(\"div\", attrs={\"id\": \"left\"})[0].get_text()\n",
    "#Output at this point is \"\\n1-50 of 8,476\\ntitles.\\n\"\n",
    "NumResults = NumResults.split()[2]\n",
    "\n",
    "NumResults = int(\"\".join(NumResults.split(',')))   #converting a string of \"8,476\" to an int of 8476\n",
    "print NumResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for i in xrange(1,50,50):\n",
    "    page=requests.get(\"http://www.imdb.com/search/title?at=0&sort=alpha&start=\"+str(i)+\"&title_type=\"+TYPE+\"&year=\"+str(YEAR_START)+\",\"+str(YEAR_END))\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    rows = soup.find(\"table\", attrs={\"class\": \"results\"}).find_all(\"tr\")[1:]\n",
    "    cleaner = lambda r: [int(r[0].get_text()), r[1].get_text(), r[2].get_text(), r[2].find(\"a\").get(\"href\")]\n",
    "    titles = titles + [(row.find(\"td\", attrs={\"class\":\"title\"}).find(\"a\").get(\"href\")) for row in rows]\n",
    "\n",
    "print len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urlcache={} #a dict to store the visited urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    # Check if URL has already been visited.\n",
    "    if (url not in urlcache) or (urlcache[url]==1) or (urlcache[url]==2):\n",
    "        time.sleep(1)\n",
    "        # try/except blocks are used whenever the code could generate an exception (e.g. division by zero).\n",
    "        # In this case we don't know if the page really exists, or even if it does, if we'll be able to reach it.\n",
    "        try:\n",
    "            r = requests.get(\"http://www.imdb.com/%s\" % url)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                urlcache[url] = r.text\n",
    "            else:\n",
    "                urlcache[url] = 1\n",
    "        except:\n",
    "            urlcache[url] = 2\n",
    "    return urlcache[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.6770000458\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for title in titles:\n",
    "    get_page(title)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print np.sum([(urlcache[k]==1) or (urlcache[k]==2) for k in urlcache])# no one or two's\n",
    "print len(titles)==len(urlcache)#we got all of the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def movie_info(url,page_text):\n",
    "    info = {}\n",
    "    info['url'] = url  \n",
    "    soup = BeautifulSoup(page_text, \"html.parser\")\n",
    "    \n",
    "    box = soup.find(\"div\", attrs={\"id\": \"full_subnav\"})\n",
    "    if box:\n",
    "        rows = box.find_all(\"li\")\n",
    "\n",
    "        for row in rows:\n",
    "            #print row\n",
    "            #print row.find(\"a\").get_text()\n",
    "            if row.find(\"a\").get_text() == \"Filming Locations\":\n",
    "                #print row.find(\"a\", attrs={\"class\": \"link ghost\"})\n",
    "                if row.find(\"a\", attrs={\"class\": \"link ghost\"}):\n",
    "                    info['location_page'] = \"None\"\n",
    "                else:\n",
    "                    loc_url = url+'locations?ref_=tt_ql_dt_6'\n",
    "                    try:\n",
    "                        r = requests.get(\"http://www.imdb.com/%s\" % loc_url)\n",
    "                        time.sleep(1)\n",
    "                        if r.status_code == 200:\n",
    "                            #print 'here'\n",
    "                            soup2 = BeautifulSoup(r.text,\"html.parser\")\n",
    "                            locations = soup2.find_all(\"div\", attrs={\"class\": \"soda\"})\n",
    "                            #print locations\n",
    "                            temp = []\n",
    "                            for location in locations:\n",
    "                                #print location\n",
    "                                temp.append(location.find(\"a\").get_text().replace(\"\\n\", \" \"))\n",
    "                            #print temp\n",
    "                            info['location_page'] = temp   \n",
    "                        else:\n",
    "                            info['location_page'] = \"fail\"\n",
    "                    except:\n",
    "                        info['location_page'] = \"fail\"\n",
    "\n",
    "    topbar = soup.find(\"table\", attrs={\"id\": \"title-overview-widget-layout\"})\n",
    "    \n",
    "    #get information from the first info box\n",
    "    if topbar:\n",
    "        infobar = topbar.find(\"div\", attrs={\"class\": \"infobar\"})\n",
    "        if infobar:\n",
    "            if infobar.find(\"meta\", attrs={\"itemprop\": \"contentRating\"}):\n",
    "                info['contentRating'] = infobar.find(\"meta\", attrs={\"itemprop\": \"contentRating\"}).get_text().split()[0]\n",
    "            if infobar.find(\"time\", attrs={\"itemprop\": \"duration\"}):\n",
    "                info['duration'] = infobar.find(\"time\", attrs={\"itemprop\": \"duration\"}).get_text().strip()\n",
    "            genres = infobar.find_all(\"span\", attrs={\"itemprop\": \"genre\"})\n",
    "            temp = []\n",
    "            for genre in genres:\n",
    "                temp.append(genre.get_text())\n",
    "            info['genre'] = temp\n",
    "            \n",
    "            #print infobar.find(\"meta\", attrs={\"itemprop\": \"datePublished\"}).\n",
    "            temp = []            \n",
    "            release_dates = infobar.find_all(\"a\", attrs={\"title\": \"See all release dates\"})\n",
    "            for dates in release_dates:\n",
    "                temp.append(dates.get_text().replace(\"\\n\", \" \"))                \n",
    "            info['release_dates'] = temp\n",
    "\n",
    "    #get name of movie\n",
    "    if topbar.find(\"td\", attrs={\"id\": \"overview-top\"}).find(\"h1\").find(\"span\", attrs={\"itemprop\":\"name\"}):\n",
    "        info['name'] = topbar.find(\"td\", attrs={\"id\": \"overview-top\"}).find(\"h1\").find(\"span\", attrs={\"itemprop\":\"name\"}).get_text()\n",
    "        info['year'] = topbar.find(\"td\", attrs={\"id\": \"overview-top\"}).find(\"h1\").find(\"span\", attrs={\"class\":\"nobr\"}).get_text()[1:-1]\n",
    "\n",
    "        \n",
    "    starbox = topbar.find(\"div\", attrs={\"class\": \"star-box-details\"})\n",
    "    if starbox:\n",
    "        if starbox.find(\"span\", attrs={\"itemprop\": \"ratingValue\"}):\n",
    "            info['user_ratings'] = starbox.find(\"span\", attrs={\"itemprop\": \"ratingValue\"}).get_text()\n",
    "        if starbox.find(\"span\", attrs={\"itemprop\": \"ratingCount\"}):\n",
    "            info['user_ratings_count'] = starbox.find(\"span\", attrs={\"itemprop\": \"ratingCount\"}).get_text()        \n",
    "        if starbox.find(\"a\", attrs={\"href\": \"criticreviews?ref_=tt_ov_rt\"}):\n",
    "            info['critic_ratings'] = starbox.find(\"a\", attrs={\"href\": \"criticreviews?ref_=tt_ov_rt\"}).get_text().strip()      \n",
    "            \n",
    "    detailsbox = soup.find(\"div\", attrs={\"id\": \"titleDetails\"})\n",
    "    if detailsbox:\n",
    "        txtblocks = detailsbox.find_all(\"div\", attrs={\"class\": \"txt-block\"})\n",
    "        for block in txtblocks:\n",
    "            #print block\n",
    "            if block.find(\"h4\"):\n",
    "                if block.find(\"h4\").get_text() == \"Country:\":\n",
    "                    info['country'] = block.find(\"a\").get_text()\n",
    "                if block.find(\"h4\").get_text() == \"Language:\":\n",
    "                    info['language'] = block.find(\"a\").get_text()\n",
    "                if block.find(\"h4\").get_text() == \"Budget:\":\n",
    "                    info['budget'] = block.get_text().split()[1]\n",
    "                if block.find(\"h4\").get_text() == \"Opening Weekend:\":\n",
    "                    info['opening_weekend'] = block.get_text().split()[2]\n",
    "                if block.find(\"h4\").get_text() == \"Gross:\":\n",
    "                    info['gross'] = block.get_text().split()[1]\n",
    "                    #print info['gross']\n",
    "               \n",
    "    \n",
    "    #print info\n",
    "    return info     \n",
    "\n",
    "#Testing Code\n",
    "#k = '/title/tt1951264/'\n",
    "#r = requests.get(\"http://www.imdb.com\"+k)\n",
    "#v = r.text\n",
    "\n",
    "#movie_info(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_info_list=[]\n",
    "\n",
    "for k,v in urlcache.items():\n",
    "    movie_info_list.append(movie_info(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd = open(\"tempdata/movieinfo.json\",\"w\")\n",
    "json.dump(movie_info_list, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(movie_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
