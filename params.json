{"name":"Data Analysis on Movie Filming Locations","tagline":"Final Project for CS 109","body":"### 1. Overview\r\nIn this project, we study the relationship between film reception and other factors like filming locations and genres. Data will be scraped from IMDB.Linear regression will be used to study the effects of each feature on user ratings. After which, Principal Component Analysis(PCA) will be used for dimensionality reduction of our data set. Then, logistic regression and k-Nearest Neighbours(kNN) will be used for classification. The accuracy of both estimators will be compared. Visualisation of results will be done via graphical plots and Tableau.\r\n\r\n### 2. Data Acquisition & Management\r\nWe first scrape the data from IMDB which gives us information about each film title such as budget, country, critic ratings, duration, genre, gross earnings, language, location, name, opening weekend earnings, release dates, url, user ratings, user ratings count and year. The code for web scraping can be found in a separate notebook. Though we planned to work with a data set of 12,000 titles initially, a preliminary test run of PCA, particularly with around 18,000 features of locations and genres, indicated that it was infeasible. Instead, we reduce the size of our data to 10,000 titles. To do so, we scraped IMDB for all film titles from 2009 to 2014. Titles without user ratings, film locations and genres are then removed from our data set. Subsequently, we pick 10,000 titles randomly from the remaining pool of titles.\r\nFirst, we convert user ratings to a binary feature where \"1\" indicates that the film was well-received while \"0\" indicates otherwise. Initially, the threshold rating for determining if a film is well-received was not \"5\" nor is it a randomly chosen number. Instead, we looked at the spread of user ratings across our data. Films with ratings in the top 50% were assigned \"1\" while films in the bottom 50% were assigned \"0\". Though such conversion of user ratings might raise problems, the intention here is to have a balanced number for both sides; additionally, this technique can be applied to larger data sets where the threshold is determined by the data in hand. However, after some considerations, it was decided that \"5\" will be taken as the threshold since, intuitively, \"5\" is the boundary most people use when deliberating whether or not they like a film.\r\nFor locations, substantial data cleaning is required. This is largely due to film locations being user-contributed. Hence, we face problems like spelling mistakes, multiple entries of similar details or details with trivial differences that were irrelevant to our study. For example, some locations are specific to the street while others merely state the country. In cleaning up the feature \"locations\", we had considered two approaches which are elaborated below.\r\n\r\n### 2.1. Approach 1\r\n\r\nWe restrict \"locations\" to cities and countries. Using a list of cities, that we acquired online, and countries across the world, we split the entries of \"locations\" for each title by the commas into phrases. This is because most entries take the form - (specific location),(city),(country) - with various titles having anomalous and repeated entries. Phrases that appear in the list of cities and countries are kept while other location details are discarded. While this resulted in some problems, one particularly interesting issue was that many countries had names shared by cities.\r\nFor example, China turned out to be the name of a city in Texas as well. As a result, if a film was filmed in China, Texas, it would be recorded as being filmed in the country China as well. However, given that these cities with similar names to countries are not especially known widely, we assume that such occurrences are rare anomalies. In addition, we chose to include countries so as to mitigate this problem since our hypothetical film will be recorded as being filmed in China and USA. As such, it is true that the film was filmed in USA but merely a rare anomaly that it is erroneously recorded to be filmed in China too.\r\nWhile Approach 2 below was also considered, Approach 1 was taken instead due to the complexity of the latter.\r\n\r\n### 2.2. Approach 2\r\nHere, we split the entries of \"locations\" by commas and treat each unique phrase as a distinct location. For example, suppose we have \"Newbury Street, Boston, USA, Boston, USA\". We split them into \"Newbury Street\", \"Boston\" and \"USA\". From a data set of around 18,000 titles, we end up with around 19,000 distinct locations as features. Then, we rely on PCA to reduce the number of features into principal components.\r\nHowever, preliminary tests concluded that the computational demands of this approach was too immense. The number of components to be reduced to by PCA was intended to explain 90% of the variation in our features. While it was possible to find that number with our data set, the first few test runs simply took too long, prompting us to turn to the first approach instead.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}